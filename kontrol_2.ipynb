{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a734f6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Database connection successful!\n",
      "INFO:__main__:Testing data size for 24 months...\n",
      "C:\\Users\\FromHell\\AppData\\Local\\Temp\\ipykernel_27956\\139884243.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  size_df = pd.read_sql(size_query, conn)\n",
      "INFO:__main__:Data size info: {'total_rows': 3941493, 'min_date': Timestamp('2023-08-01 00:00:00'), 'max_date': Timestamp('2025-08-24 00:00:00'), 'unique_dates': 755}\n",
      "INFO:__main__:Testing sample aggregated data...\n",
      "C:\\Users\\FromHell\\AppData\\Local\\Temp\\ipykernel_27956\\139884243.py:53: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sample_df = pd.read_sql(sample_query, conn)\n",
      "INFO:__main__:Sample data shape: (10, 7)\n",
      "INFO:__main__:Sample data:\n",
      "        date store_code        product_id  discount_amount  net_amount_wovat  \\\n",
      "0 2023-08-01       0101  101295860BEYAZ43             0.00           1509.08   \n",
      "1 2023-08-01       0101  101330069BEYAZ40            45.30            956.34   \n",
      "2 2023-08-01       0101  101330211BEYAZ39             0.00           1636.34   \n",
      "3 2023-08-01       0101  101342567BEYAZ42            28.24           1327.26   \n",
      "4 2023-08-01       0101   101369449LACI43             0.00            563.62   \n",
      "\n",
      "   net_quantity  unit_price  \n",
      "0           2.0      754.54  \n",
      "1           2.0      478.17  \n",
      "2           2.0      818.17  \n",
      "3           2.0      663.63  \n",
      "4           2.0      281.81  \n",
      "INFO:__main__:Testing other tables...\n",
      "C:\\Users\\FromHell\\AppData\\Local\\Temp\\ipykernel_27956\\139884243.py:61: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  product_count = pd.read_sql(product_query, conn)\n",
      "INFO:__main__:Product count: 413262\n",
      "C:\\Users\\FromHell\\AppData\\Local\\Temp\\ipykernel_27956\\139884243.py:65: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  cluster_count = pd.read_sql(cluster_query, conn)\n",
      "INFO:__main__:Store cluster count: 23\n",
      "C:\\Users\\FromHell\\AppData\\Local\\Temp\\ipykernel_27956\\139884243.py:69: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  calendar_count = pd.read_sql(calendar_query, conn)\n",
      "INFO:__main__:Calendar count: 3287\n",
      "INFO:__main__:All tests completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import logging\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def test_db_connection():\n",
    "    \"\"\"Test database connection and run queries\"\"\"\n",
    "    try:\n",
    "        # Connect to Genboost database\n",
    "        conn = pymysql.connect(\n",
    "            host='10.0.0.46',\n",
    "            user='Merchflow',\n",
    "            password='Gen_Merch2024!+',\n",
    "            database='Genboost',\n",
    "            charset='utf8mb4'\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Database connection successful!\")\n",
    "        \n",
    "        # Test 1: Data size check for 24 months\n",
    "        logger.info(\"Testing data size for 24 months...\")\n",
    "        size_query = \"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_rows,\n",
    "            MIN(`date`) as min_date,\n",
    "            MAX(`date`) as max_date,\n",
    "            COUNT(DISTINCT `date`) as unique_dates\n",
    "        FROM Genboost.history_sales \n",
    "        WHERE `date` >= DATE_FORMAT(DATE_SUB(CURDATE(), INTERVAL 24 MONTH), '%Y-%m-01')\n",
    "        \"\"\"\n",
    "        \n",
    "        size_df = pd.read_sql(size_query, conn)\n",
    "        logger.info(f\"Data size info: {size_df.to_dict('records')[0]}\")\n",
    "        \n",
    "        # Test 2: Sample aggregated data\n",
    "        logger.info(\"Testing sample aggregated data...\")\n",
    "        sample_query = \"\"\"\n",
    "        SELECT \n",
    "            date, store_code, product_id,\n",
    "            SUM(discount_amount) as discount_amount,\n",
    "            SUM(net_amount_wovat) as net_amount_wovat,\n",
    "            SUM(net_quantity) as net_quantity,\n",
    "            SUM(net_amount_wovat) / SUM(net_quantity) as unit_price\n",
    "        FROM Genboost.history_sales\n",
    "        WHERE `date` >= DATE_FORMAT(DATE_SUB(CURDATE(), INTERVAL 24 MONTH), '%Y-%m-01')\n",
    "        GROUP BY date, store_code, product_id\n",
    "        LIMIT 10\n",
    "        \"\"\"\n",
    "        \n",
    "        sample_df = pd.read_sql(sample_query, conn)\n",
    "        logger.info(f\"Sample data shape: {sample_df.shape}\")\n",
    "        logger.info(f\"Sample data:\\n{sample_df.head()}\")\n",
    "        \n",
    "        # Test 3: Other tables\n",
    "        logger.info(\"Testing other tables...\")\n",
    "        \n",
    "        product_query = \"SELECT COUNT(*) as product_count FROM Genboost.dim_product\"\n",
    "        product_count = pd.read_sql(product_query, conn)\n",
    "        logger.info(f\"Product count: {product_count.iloc[0]['product_count']}\")\n",
    "        \n",
    "        cluster_query = \"SELECT COUNT(*) as cluster_count FROM Genboost.store_clustering\"\n",
    "        cluster_count = pd.read_sql(cluster_query, conn)\n",
    "        logger.info(f\"Store cluster count: {cluster_count.iloc[0]['cluster_count']}\")\n",
    "        \n",
    "        calendar_query = \"SELECT COUNT(*) as calendar_count FROM Genboost.dim_calendar\"\n",
    "        calendar_count = pd.read_sql(calendar_query, conn)\n",
    "        logger.info(f\"Calendar count: {calendar_count.iloc[0]['calendar_count']}\")\n",
    "        \n",
    "        conn.close()\n",
    "        logger.info(\"All tests completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_db_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45ed9c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FromHell\\AppData\\Local\\Temp\\ipykernel_20100\\2842824848.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam satır: 1476481\n",
      "      date store_code                product_id  discount_amount  net_amount_wovat  net_quantity  unit_price\n",
      "2023-08-01       0101          101295860BEYAZ43             0.00           1509.08           2.0      754.54\n",
      "2023-08-01       0101          101330069BEYAZ40            45.30            956.34           2.0      478.17\n",
      "2023-08-01       0101          101330211BEYAZ39             0.00           1636.34           2.0      818.17\n",
      "2023-08-01       0101          101342567BEYAZ42            28.24           1327.26           2.0      663.63\n",
      "2023-08-01       0101           101369449LACI43             0.00            563.62           2.0      281.81\n",
      "2023-08-01       0101           101373117HAKI41             0.00            599.98           2.0      299.99\n",
      "2023-08-01       0101      11016-6ENPepper42-43             0.00           1834.54           2.0      917.27\n",
      "2023-08-01       0101        12228020-WHTWhiteL             0.00           1272.70           2.0      636.35\n",
      "2023-08-01       0101      190107002-NGTNIGHTXL             0.00            599.98           2.0      299.99\n",
      "2023-08-01       0101 190107002-SNWSNOW-WHITEXL             0.00            599.98           2.0      299.99\n",
      "\n",
      "İlk 5 satır tekrar:\n",
      "      date store_code       product_id  discount_amount  net_amount_wovat  net_quantity  unit_price\n",
      "2023-08-01       0101 101295860BEYAZ43             0.00           1509.08           2.0      754.54\n",
      "2023-08-01       0101 101330069BEYAZ40            45.30            956.34           2.0      478.17\n",
      "2023-08-01       0101 101330211BEYAZ39             0.00           1636.34           2.0      818.17\n",
      "2023-08-01       0101 101342567BEYAZ42            28.24           1327.26           2.0      663.63\n",
      "2023-08-01       0101  101369449LACI43             0.00            563.62           2.0      281.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import traceback\n",
    "\n",
    "def run_query(query: str) -> pd.DataFrame | None:\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = pymysql.connect(\n",
    "            host='10.0.0.46',\n",
    "            user='Merchflow',\n",
    "            password='Gen_Merch2024!+',\n",
    "            database='Genboost',\n",
    "            charset='utf8mb4'\n",
    "        )\n",
    "        df = pd.read_sql(query, conn)\n",
    "        # Örnek çıktı\n",
    "        print(f\"Toplam satır: {len(df)}\")\n",
    "        print(df.head(10).to_string(index=False))\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"Hata:\", e)\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT \n",
    "            date, store_code, product_id,\n",
    "            SUM(discount_amount) as discount_amount,\n",
    "            SUM(net_amount_wovat) as net_amount_wovat,\n",
    "            SUM(net_quantity) as net_quantity,\n",
    "            SUM(net_amount_wovat) / SUM(net_quantity) as unit_price\n",
    "        FROM Genboost.history_sales\n",
    "        WHERE `date` >= DATE_FORMAT(DATE_SUB(CURDATE(), INTERVAL 24 MONTH), '%Y-%m-01')\n",
    "        GROUP BY date, store_code, product_id\n",
    "\"\"\"\n",
    "\n",
    "df = run_query(query)\n",
    "\n",
    "# İstersen burada da kontrol edebilirsin:\n",
    "if df is not None:\n",
    "    print(\"\\nİlk 5 satır tekrar:\")\n",
    "    print(df.head().to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4934949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql, csv, re\n",
    "\n",
    "def _detect_csv_format(path, encoding=\"utf-8\"):\n",
    "    # İlk birkaç KB ile ayraç ve başlık var mı tespit et\n",
    "    with open(path, \"r\", encoding=encoding, newline=\"\") as f:\n",
    "        sample = f.read(4096)\n",
    "        try:\n",
    "            sniffer = csv.Sniffer()\n",
    "            dialect = sniffer.sniff(sample, delimiters=[\",\",\";\",\"\\t\",\"|\"])\n",
    "            has_header = sniffer.has_header(sample)\n",
    "            delimiter = dialect.delimiter\n",
    "        except Exception:\n",
    "            # fallback: ; sık görülür\n",
    "            delimiter, has_header = \";\", True\n",
    "    # Satır sonu tahmini\n",
    "    if \"\\r\\n\" in sample:\n",
    "        lineterm = r\"\\r\\n\"\n",
    "    else:\n",
    "        lineterm = r\"\\n\"\n",
    "    return delimiter, has_header, lineterm\n",
    "\n",
    "def _sanitize_mysql_ident(name: str, maxlen=60):\n",
    "    name = name.strip().replace(\"\\ufeff\",\"\")     # BOM temizle\n",
    "    name = re.sub(r\"\\s+\", \"_\", name)             # boşluk -> _\n",
    "    name = re.sub(r\"[^\\w$]\", \"_\", name)          # harf/rakam/_ dışı -> _\n",
    "    if name and name[0].isdigit():\n",
    "        name = \"_\" + name\n",
    "    return name[:maxlen] or \"_col\"\n",
    "\n",
    "def upload_csv_fast(csv_path, table_name, encoding=\"utf-8\"):\n",
    "    # 0) CSV biçimini algıla\n",
    "    delim, has_header, lineterm = _detect_csv_format(csv_path, encoding=encoding)\n",
    "\n",
    "    # 1) Başlıkları doğru ayraçla oku\n",
    "    df_head = pd.read_csv(csv_path, nrows=0, sep=delim, engine=\"python\", encoding=encoding)\n",
    "    raw_cols = df_head.columns.tolist()\n",
    "\n",
    "    # 2) Kolon adlarını güvenli hale getir + çakışma çöz\n",
    "    safe_cols, used = [], set()\n",
    "    for c in raw_cols:\n",
    "        s = _sanitize_mysql_ident(c)\n",
    "        base, k = s, 1\n",
    "        while s in used:\n",
    "            suff = f\"_{k}\"\n",
    "            s = (base[: max(1, 60 - len(suff))] + suff)\n",
    "            k += 1\n",
    "        used.add(s)\n",
    "        safe_cols.append(s)\n",
    "\n",
    "    col_defs = \",\\n  \".join(f\"`{c}` TEXT\" for c in safe_cols)  # hızlı başlangıç: TEXT\n",
    "    col_list = \",\".join(f\"`{c}`\" for c in safe_cols)\n",
    "\n",
    "    # 3) MySQL'e bağlan\n",
    "    conn = pymysql.connect(\n",
    "        host='10.0.0.46',\n",
    "        user='Merchflow',\n",
    "        password='Gen_Merch2024!+',\n",
    "        database='Genboost',\n",
    "        charset='utf8mb4',\n",
    "        local_infile=True\n",
    "    )\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SET SESSION local_infile=1;\")\n",
    "            # 4) Tabloyu oluştur (yoksa)\n",
    "            create_sql = f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS `{table_name}` (\n",
    "              {col_defs}\n",
    "            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "            \"\"\"\n",
    "            cur.execute(create_sql)\n",
    "\n",
    "            # 5) LOAD DATA — ayraç/satır sonu dinamik\n",
    "            mysql_delim = {\"\\t\": r\"\\t\"}.get(delim, delim)  # \\t kaçış\n",
    "            load_sql = f\"\"\"\n",
    "            LOAD DATA LOCAL INFILE %s\n",
    "            INTO TABLE `{table_name}`\n",
    "            CHARACTER SET utf8mb4\n",
    "            FIELDS TERMINATED BY '{mysql_delim}'\n",
    "            OPTIONALLY ENCLOSED BY '\"'\n",
    "            ESCAPED BY '\\\\\\\\'\n",
    "            LINES TERMINATED BY '{lineterm}'\n",
    "            {\"IGNORE 1 LINES\" if has_header else \"\"}\n",
    "            ({col_list});\n",
    "            \"\"\"\n",
    "            cur.execute(load_sql, (csv_path,))\n",
    "        conn.commit()\n",
    "        print(f\"Yüklendi → Genboost.{table_name}  (kolon sayısı: {len(safe_cols)}, ayraç: '{delim}')\")\n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea101df6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(1229, \"Variable 'local_infile' is a GLOBAL variable and should be set with SET GLOBAL\")",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m CSV_PATH = \u001b[33m\"\u001b[39m\u001b[33mreplenishment_results.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m TABLE_NAME = \u001b[33m\"\u001b[39m\u001b[33mreplenishment_results\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mupload_csv_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCSV_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTABLE_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mupload_csv_fast\u001b[39m\u001b[34m(csv_path, table_name, encoding)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m conn.cursor() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m         \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSET SESSION local_infile=1;\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m         \u001b[38;5;66;03m# 4) Tabloyu oluştur (yoksa)\u001b[39;00m\n\u001b[32m     67\u001b[39m         create_sql = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[33m        CREATE TABLE IF NOT EXISTS `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` (\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[33m          \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_defs\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[33m        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FromHell\\Desktop\\sporthink_ar - Kopya\\venv\\Lib\\site-packages\\pymysql\\cursors.py:153\u001b[39m, in \u001b[36mCursor.execute\u001b[39m\u001b[34m(self, query, args)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    151\u001b[39m query = \u001b[38;5;28mself\u001b[39m.mogrify(query, args)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m._executed = query\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FromHell\\Desktop\\sporthink_ar - Kopya\\venv\\Lib\\site-packages\\pymysql\\cursors.py:322\u001b[39m, in \u001b[36mCursor._query\u001b[39m\u001b[34m(self, q)\u001b[39m\n\u001b[32m    320\u001b[39m conn = \u001b[38;5;28mself\u001b[39m._get_db()\n\u001b[32m    321\u001b[39m \u001b[38;5;28mself\u001b[39m._clear_result()\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m._do_get_result()\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rowcount\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FromHell\\Desktop\\sporthink_ar - Kopya\\venv\\Lib\\site-packages\\pymysql\\connections.py:575\u001b[39m, in \u001b[36mConnection.query\u001b[39m\u001b[34m(self, sql, unbuffered)\u001b[39m\n\u001b[32m    573\u001b[39m     sql = sql.encode(\u001b[38;5;28mself\u001b[39m.encoding, \u001b[33m\"\u001b[39m\u001b[33msurrogateescape\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    574\u001b[39m \u001b[38;5;28mself\u001b[39m._execute_command(COMMAND.COM_QUERY, sql)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m \u001b[38;5;28mself\u001b[39m._affected_rows = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_query_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._affected_rows\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FromHell\\Desktop\\sporthink_ar - Kopya\\venv\\Lib\\site-packages\\pymysql\\connections.py:826\u001b[39m, in \u001b[36mConnection._read_query_result\u001b[39m\u001b[34m(self, unbuffered)\u001b[39m\n\u001b[32m    824\u001b[39m     result.init_unbuffered_query()\n\u001b[32m    825\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[38;5;28mself\u001b[39m._result = result\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.server_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FromHell\\Desktop\\sporthink_ar - Kopya\\venv\\Lib\\site-packages\\pymysql\\connections.py:1203\u001b[39m, in \u001b[36mMySQLResult.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1202\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1203\u001b[39m         first_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1205\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m first_packet.is_ok_packet():\n\u001b[32m   1206\u001b[39m             \u001b[38;5;28mself\u001b[39m._read_ok_packet(first_packet)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FromHell\\Desktop\\sporthink_ar - Kopya\\venv\\Lib\\site-packages\\pymysql\\connections.py:782\u001b[39m, in \u001b[36mConnection._read_packet\u001b[39m\u001b[34m(self, packet_type)\u001b[39m\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.unbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    781\u001b[39m         \u001b[38;5;28mself\u001b[39m._result.unbuffered_active = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     \u001b[43mpacket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FromHell\\Desktop\\sporthink_ar - Kopya\\venv\\Lib\\site-packages\\pymysql\\protocol.py:219\u001b[39m, in \u001b[36mMysqlPacket.raise_for_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33merrno =\u001b[39m\u001b[33m\"\u001b[39m, errno)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\FromHell\\Desktop\\sporthink_ar - Kopya\\venv\\Lib\\site-packages\\pymysql\\err.py:150\u001b[39m, in \u001b[36mraise_mysql_exception\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     errorclass = InternalError \u001b[38;5;28;01mif\u001b[39;00m errno < \u001b[32m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[31mOperationalError\u001b[39m: (1229, \"Variable 'local_infile' is a GLOBAL variable and should be set with SET GLOBAL\")"
     ]
    }
   ],
   "source": [
    "CSV_PATH = \"replenishment_results.csv\"\n",
    "TABLE_NAME = \"replenishment_results\"\n",
    "upload_csv_fast(CSV_PATH, TABLE_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
